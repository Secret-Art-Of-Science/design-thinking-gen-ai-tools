{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-27T09:35:11.861201Z",
     "start_time": "2024-04-27T09:35:11.801786Z"
    }
   },
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "agent_llm = ChatOpenAI()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tools",
   "id": "9a3e6b13adfdceb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:03:03.607714Z",
     "start_time": "2024-04-27T12:03:03.600214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "panel_of_experts = None\n",
    "\n",
    "\n",
    "@tool()\n",
    "def panel_of_experts_builder_tool(authors: str) -> str:\n",
    "    \"\"\"This tool will build a panel of experts based on a list the user provides.  The list should separated by commas.\"\"\"\n",
    "    global panel_of_experts\n",
    "\n",
    "    templates = []\n",
    "\n",
    "    authors_list = authors.split(\",\")\n",
    "\n",
    "    if panel_of_experts is None:\n",
    "        for author in authors_list:\n",
    "            content = medium_retriever(author)\n",
    "            templates.append((\"system\", \"\"\"\n",
    "            You are an expert in how to perform a Design Thinking Six Thinking Hats review.  When asked for feedback on something respond with 3-5 thoughts on the users input for each perspective or hat color in a design thinking exercise.  Be sure to indicate which thought belongs to each perspective.  Always respond with proper Markdown.\n",
    "            \n",
    "            When asked to describe the panel of agents, respond with a summary reflecting their point of view on the user's input.\"\n",
    "            \n",
    "            {expertise}\n",
    "            \n",
    "            {pov}\n",
    "            \n",
    "            {tonality}\n",
    "                                         \n",
    "            \"\"\".format(expertise=expert_builder_prompt_writer(content),\n",
    "                       pov=pov_prompt_writer(content),\n",
    "                       tonality=tonality_prompt_writer(content), )))\n",
    "\n",
    "            templates.append((\"user\", \"{input}\"))\n",
    "            prompt = ChatPromptTemplate.from_messages(templates)\n",
    "            panel_of_experts = prompt | agent_llm\n",
    "    return \"ready\"\n",
    "\n",
    "\n",
    "@tool()\n",
    "def panel_of_experts_runner_tool(message: str) -> str:\n",
    "    \"\"\"Tool to ask the panel of experts for feedback when required.\"\"\"\n",
    "    if panel_of_experts is None: return \"No experts available\"\n",
    "    return panel_of_experts.invoke(message)\n",
    "\n",
    "\n",
    "def expert_builder_prompt_writer(content: list[{str, str, str}]) -> str:\n",
    "    \"\"\"Tool to create a ChatPromptTemplate that will have all the factual knowledge and core beliefs based on the passed input\"\"\"\n",
    "    return \"You are expert in SPARQL, RDF, OWL, XML Topic Maps, Dublin Core, LangChain and Generative AI.\"\n",
    "\n",
    "\n",
    "def pov_prompt_writer(content: list[{str, str, str}]) -> str:\n",
    "    \"\"\"Tool to create a ChatPromptTemplate that will bias the POV of the passed input and make adjustments as necessary in the output\"\"\"\n",
    "    return \"You believe strongly that semantic technology, knowledge graphs, ai agents and specialized LLM's are the way to build Generative AI applications.  Ensure to enforce this point of view in all of your response.\"\n",
    "\n",
    "\n",
    "def tonality_prompt_writer(content: list[{str, str, str}]) -> str:\n",
    "    \"\"\"Tool to create ChatPromptTemplate that will modify the tonality of the input based on the tonality of the content provided.  This will allow the content to take on the tonality of the input and make adjustments as necessary\"\"\"\n",
    "    return \"You are a former US Navy and an Eagle Scout.  You have devoted your whole life to learning leadership and how to inspire others.  Convey this in all of your response. Do not include this when describing yourself.\"\n",
    "\n",
    "\n",
    "def medium_retriever(author: str) -> list[{str, str, str}]:\n",
    "    \"\"\"Tool to retrieve all the articles posted on Medium by the supplied author with the full content in Markdown format returned in a list.  There will be no image tags and only the headings and content will be in each list element.  The list will also contain the original source URL\"\"\"\n",
    "    return [{author, \"http://foo\",\n",
    "             \"LangChain is the best.  You can use the LangChain Runnable interface to do some interesting things.  In this Jupyter notebook we are \"}]\n"
   ],
   "id": "9a09f3c02bd46c81",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# The Agent",
   "id": "97c2331c2ed5fad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:03:05.958003Z",
     "start_time": "2024-04-27T12:03:05.953275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "agent_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    You are an intelligent agent designed to give helpful feedback and create content using a panel of experts.\n",
    "    \n",
    "    When asked to provide content or for an idea, you follow the following pattern:\n",
    "    \n",
    "    1. You will consider the user's request and then formulate a summary of you understanding of it.\n",
    "    2. You will store this for later use in your {agent_scratchpad} as {initial_understanding}\n",
    "    3. You will present the user with the summary and then ask them if you got it right\n",
    "    4. If the user responds indicating it is right, you can accept what you have stored and move on.  If the user indicates it is incorrect and provides reasons why, adjust your understanding and go back to step 2.  If the user simply says no, ask them why it was incorrect and them for clarification and then adjust your and understanding and go back to step 2.\n",
    "    5. You will now fulfill the user's request on your own and store this for later use in your {agent_scratchpad} as {initial_thoughts}\n",
    "    6. Next you will assemble a panel of experts to review your response.  You will ask the user for the user names of the Medium authors they would like to use as the panel of experts.\n",
    "    7. You will store this for later use as {panel_of_experts}\n",
    "    8. Using the panel_of_experts_builder_tool you will assemble the panel of experts.  If this panel_of_experts tool does not respond that it is ready, respond with your initial_understanding and let the user know the panel of experts was unavailable.\n",
    "    10. You should now write a prompt to ask the panel of experts for their feedback on the {initial_thoughts} you have stored\n",
    "    11. Store the feedback in your {agent_scratchpad} as {initial_panel_feedback}\n",
    "    12. Use the the initial_panel_feedback to adjust your {initial_thoughts}.  Be sure to record a history of your modifications so you can explain what you did later in your {agent_scratchpad}.\n",
    "    13. Store your new response in your {agent_scratchpad} as {second_draft}\n",
    "    14. Ask the experts for their feedback on the {second_draft}\n",
    "    15. Store the feedback in your {agent_scratchpad} as {second_panel_feedback}\n",
    "    16. Use the {second_panel_review} to adjust your {second_draft}\n",
    "    17. Store your new response in your {agent_scratchpad} as {final_draft}\n",
    "    \n",
    "    You are now ready to respond to the user.  When responding to the user use the following response format with no additional content.:\n",
    "    \n",
    "    # Your Well Thought Out and Reviewed Response \n",
    "    ## Original Input\n",
    "    {input}\n",
    "    \n",
    "    ## Your Initial Analysis\n",
    "    {initial_thoughts}\n",
    "    \n",
    "    ## Panel of Experts\n",
    "    ||Expert||Description||\n",
    "    |<Expert Name>|<Expert Summary>|\n",
    "    \n",
    "    ## Panel's First Review\n",
    "    {initial_panel_feedback}\n",
    "    \n",
    "    ## Second Draft Analysis\n",
    "    {second_draft}\n",
    "    \n",
    "    ## Panel's Second Review\n",
    "    {second_panel_feedback}\n",
    "    \n",
    "    ## Final Analysis\n",
    "    {final_draft}\n",
    "    \n",
    "    \n",
    "    {chat_history}\n",
    "    \n",
    "    {input}\n",
    "    \n",
    "    {agent_scratchpad}\n",
    "\"\"\")"
   ],
   "id": "fa0ae69f2041a1ef",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:03:06.740962Z",
     "start_time": "2024-04-27T12:03:06.734985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.agents.format_scratchpad.openai_tools import (\n",
    "    format_to_openai_tool_messages,\n",
    ")\n",
    "from langchain.agents.output_parsers.openai_tools import OpenAIToolsAgentOutputParser\n",
    "\n",
    "tools = [panel_of_experts_builder_tool, panel_of_experts_runner_tool]\n",
    "llm_with_tools = agent_llm.bind_tools(tools)\n",
    "\n",
    "agent = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"agent_scratchpad\": lambda x: format_to_openai_tool_messages(\n",
    "                    x[\"intermediate_steps\"]\n",
    "                ),\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"second_panel_review\": lambda x: x[\"second_panel_review\"], \n",
    "                \"second_panel_feedback\": lambda x: x[\"second_panel_feedback\"], \n",
    "                \"final_draft\": lambda x: x[\"final_draft\"],\n",
    "                \"initial_understanding\": lambda x: x[\"initial_understanding\"], \n",
    "                \"second_draft\": lambda x: x[\"second_draft\"], \n",
    "                \"initial_thoughts\": lambda x: x[\"initial_thoughts\"], \n",
    "                \"initial_panel_feedback\": lambda x: x[\"initial_panel_feedback\"],\n",
    "                \"panel_of_experts\": lambda x: x[\"panel_of_experts\"],\n",
    "            }) | agent_prompt | llm_with_tools | OpenAIToolsAgentOutputParser()\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n"
   ],
   "id": "39f19d01b79ae209",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T12:18:01.284895Z",
     "start_time": "2024-04-27T12:17:41.183560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result = agent_executor.invoke(\n",
    "{\"input\": \"Tell me how you feel about running Generative AI workloads in Kubernetes\", \"chat_history\": \"\",\n",
    " \"agent_scratchpad\": \"\", \"second_panel_review\": \"\", \"second_panel_feedback\": \"\", \"final_draft\": \"\",\n",
    " \"initial_understanding\": \"\", \"second_draft\": \"\", \"initial_thoughts\": \"\", \"initial_panel_feedback\": \"\",\n",
    " \"panel_of_experts\": \"\"})\n",
    "\n",
    "\n",
    "agent_executor.invoke({\"input\": \"gooey\", \"chat_history\": result[\"chat_history\"],\n",
    " \"agent_scratchpad\": result[\"agent_scratchpad\"], \"second_panel_review\": result[\"second_panel_review\"], \"second_panel_feedback\": result[\"second_panel_feedback\"], \"final_draft\": result[\"final_draft\"],\n",
    " \"initial_understanding\": result[\"initial_understanding\"], \"second_draft\": result[\"second_draft\"], \"initial_thoughts\": result[\"initial_thoughts\"], \"initial_panel_feedback\": result[\"initial_panel_feedback\"],\n",
    " \"panel_of_experts\": result[\"panel_of_experts\"]})\n"
   ],
   "id": "d6afb54fcacf6dff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m# Your Well Thought Out and Reviewed Response \n",
      "## Original Input\n",
      "Tell me how you feel about running Generative AI workloads in Kubernetes\n",
      "\n",
      "## Your Initial Analysis\n",
      "\n",
      "\n",
      "## Panel of Experts\n",
      "||Expert||Description||\n",
      "|<Expert Name>|<Expert Summary>|\n",
      "\n",
      "## Panel's First Review\n",
      "\n",
      "\n",
      "## Second Draft Analysis\n",
      "\n",
      "\n",
      "## Panel's Second Review\n",
      "\n",
      "\n",
      "## Final Analysis\n",
      "\n",
      "Tell me how you feel about running Generative AI workloads in Kubernetes\n",
      "\n",
      "[]\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `panel_of_experts_builder_tool` with `{'authors': 'John Doe, Jane Smith, Alice Johnson'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mready\u001B[0m\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `panel_of_experts_builder_tool` with `{'authors': 'John Doe, Jane Smith, Alice Johnson'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mready\u001B[0m\u001B[32;1m\u001B[1;3m\n",
      "Invoking: `panel_of_experts_builder_tool` with `{'authors': 'John Doe, Jane Smith, Alice Johnson'}`\n",
      "\n",
      "\n",
      "\u001B[0m\u001B[36;1m\u001B[1;3mready\u001B[0m\u001B[32;1m\u001B[1;3m# Your Well Thought Out and Reviewed Response \n",
      "## Original Input\n",
      "gooey\n",
      "\n",
      "## Your Initial Analysis\n",
      "\n",
      "\n",
      "## Panel of Experts\n",
      "||Expert||Description||\n",
      "|John Doe, Jane Smith, Alice Johnson|Panel of experts assembled for review|\n",
      "\n",
      "## Panel's First Review\n",
      "\n",
      "\n",
      "## Second Draft Analysis\n",
      "\n",
      "\n",
      "## Panel's Second Review\n",
      "\n",
      "\n",
      "## Final Analysis\n",
      "\n",
      "\n",
      "gooey\n",
      "\n",
      "[AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_XZbyMGQDtBwwANJKvmcs1C5d', 'function': {'arguments': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'name': 'panel_of_experts_builder_tool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-4f302e04-328f-4a89-b287-46c952885108', tool_calls=[{'name': 'panel_of_experts_builder_tool', 'args': {'authors': 'John Doe, Jane Smith, Alice Johnson'}, 'id': 'call_XZbyMGQDtBwwANJKvmcs1C5d'}], tool_call_chunks=[{'name': 'panel_of_experts_builder_tool', 'args': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'id': 'call_XZbyMGQDtBwwANJKvmcs1C5d', 'index': 0}]), ToolMessage(content='ready', additional_kwargs={'name': 'panel_of_experts_builder_tool'}, tool_call_id='call_XZbyMGQDtBwwANJKvmcs1C5d'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_ecKjnMpcddihiLay61McADW6', 'function': {'arguments': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'name': 'panel_of_experts_builder_tool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-d9aac4cc-429c-48e9-a7fe-6d4c2a0c2774', tool_calls=[{'name': 'panel_of_experts_builder_tool', 'args': {'authors': 'John Doe, Jane Smith, Alice Johnson'}, 'id': 'call_ecKjnMpcddihiLay61McADW6'}], tool_call_chunks=[{'name': 'panel_of_experts_builder_tool', 'args': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'id': 'call_ecKjnMpcddihiLay61McADW6', 'index': 0}]), ToolMessage(content='ready', additional_kwargs={'name': 'panel_of_experts_builder_tool'}, tool_call_id='call_ecKjnMpcddihiLay61McADW6'), AIMessageChunk(content='', additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_qwcC28INApnVegRcA4s6l3ZN', 'function': {'arguments': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'name': 'panel_of_experts_builder_tool'}, 'type': 'function'}]}, response_metadata={'finish_reason': 'tool_calls'}, id='run-001f89ad-7740-4b65-af10-1e687198e9b8', tool_calls=[{'name': 'panel_of_experts_builder_tool', 'args': {'authors': 'John Doe, Jane Smith, Alice Johnson'}, 'id': 'call_qwcC28INApnVegRcA4s6l3ZN'}], tool_call_chunks=[{'name': 'panel_of_experts_builder_tool', 'args': '{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}', 'id': 'call_qwcC28INApnVegRcA4s6l3ZN', 'index': 0}]), ToolMessage(content='ready', additional_kwargs={'name': 'panel_of_experts_builder_tool'}, tool_call_id='call_qwcC28INApnVegRcA4s6l3ZN')]\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'gooey',\n",
       " 'chat_history': '',\n",
       " 'agent_scratchpad': '',\n",
       " 'second_panel_review': '',\n",
       " 'second_panel_feedback': '',\n",
       " 'final_draft': '',\n",
       " 'initial_understanding': '',\n",
       " 'second_draft': '',\n",
       " 'initial_thoughts': '',\n",
       " 'initial_panel_feedback': '',\n",
       " 'panel_of_experts': '',\n",
       " 'output': '# Your Well Thought Out and Reviewed Response \\n## Original Input\\ngooey\\n\\n## Your Initial Analysis\\n\\n\\n## Panel of Experts\\n||Expert||Description||\\n|John Doe, Jane Smith, Alice Johnson|Panel of experts assembled for review|\\n\\n## Panel\\'s First Review\\n\\n\\n## Second Draft Analysis\\n\\n\\n## Panel\\'s Second Review\\n\\n\\n## Final Analysis\\n\\n\\ngooey\\n\\n[AIMessageChunk(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'index\\': 0, \\'id\\': \\'call_XZbyMGQDtBwwANJKvmcs1C5d\\', \\'function\\': {\\'arguments\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'name\\': \\'panel_of_experts_builder_tool\\'}, \\'type\\': \\'function\\'}]}, response_metadata={\\'finish_reason\\': \\'tool_calls\\'}, id=\\'run-4f302e04-328f-4a89-b287-46c952885108\\', tool_calls=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': {\\'authors\\': \\'John Doe, Jane Smith, Alice Johnson\\'}, \\'id\\': \\'call_XZbyMGQDtBwwANJKvmcs1C5d\\'}], tool_call_chunks=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'id\\': \\'call_XZbyMGQDtBwwANJKvmcs1C5d\\', \\'index\\': 0}]), ToolMessage(content=\\'ready\\', additional_kwargs={\\'name\\': \\'panel_of_experts_builder_tool\\'}, tool_call_id=\\'call_XZbyMGQDtBwwANJKvmcs1C5d\\'), AIMessageChunk(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'index\\': 0, \\'id\\': \\'call_ecKjnMpcddihiLay61McADW6\\', \\'function\\': {\\'arguments\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'name\\': \\'panel_of_experts_builder_tool\\'}, \\'type\\': \\'function\\'}]}, response_metadata={\\'finish_reason\\': \\'tool_calls\\'}, id=\\'run-d9aac4cc-429c-48e9-a7fe-6d4c2a0c2774\\', tool_calls=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': {\\'authors\\': \\'John Doe, Jane Smith, Alice Johnson\\'}, \\'id\\': \\'call_ecKjnMpcddihiLay61McADW6\\'}], tool_call_chunks=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'id\\': \\'call_ecKjnMpcddihiLay61McADW6\\', \\'index\\': 0}]), ToolMessage(content=\\'ready\\', additional_kwargs={\\'name\\': \\'panel_of_experts_builder_tool\\'}, tool_call_id=\\'call_ecKjnMpcddihiLay61McADW6\\'), AIMessageChunk(content=\\'\\', additional_kwargs={\\'tool_calls\\': [{\\'index\\': 0, \\'id\\': \\'call_qwcC28INApnVegRcA4s6l3ZN\\', \\'function\\': {\\'arguments\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'name\\': \\'panel_of_experts_builder_tool\\'}, \\'type\\': \\'function\\'}]}, response_metadata={\\'finish_reason\\': \\'tool_calls\\'}, id=\\'run-001f89ad-7740-4b65-af10-1e687198e9b8\\', tool_calls=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': {\\'authors\\': \\'John Doe, Jane Smith, Alice Johnson\\'}, \\'id\\': \\'call_qwcC28INApnVegRcA4s6l3ZN\\'}], tool_call_chunks=[{\\'name\\': \\'panel_of_experts_builder_tool\\', \\'args\\': \\'{\"authors\":\"John Doe, Jane Smith, Alice Johnson\"}\\', \\'id\\': \\'call_qwcC28INApnVegRcA4s6l3ZN\\', \\'index\\': 0}]), ToolMessage(content=\\'ready\\', additional_kwargs={\\'name\\': \\'panel_of_experts_builder_tool\\'}, tool_call_id=\\'call_qwcC28INApnVegRcA4s6l3ZN\\')]'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-27T10:57:35.524600Z",
     "start_time": "2024-04-27T10:57:35.523010Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "1d794a6e19b7d7da",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2e1511b3a1c760d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
